{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    IPython notebook for running a trivial OpenCL program\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either set the __file__ attribute or pass filename to run_pytest\n",
    "__file__ = 'PyTest.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from ipytest import run_pytest, clean_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation for pytest\n",
    "https://docs.pytest.org/en/latest/reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'Tesla K80'\n",
      " => compute capability: (3, 7)\n",
      " => memory: 11307 / 11441 MB available\n"
     ]
    }
   ],
   "source": [
    "#Initialize CUDA - must be first call to CUDA!\n",
    "cuda_driver.init()\n",
    "\n",
    "#Create CUDA context\n",
    "cuda_device = cuda_driver.Device(0)\n",
    "print(\"Using '{:s}'\".format(cuda_device.name()))\n",
    "print(\" => compute capability: {:s}\".format(str(cuda_device.compute_capability())))\n",
    "context = cuda_device.make_context()\n",
    "free, total = cuda_driver.mem_get_info()\n",
    "\n",
    "print(\" => memory: {:d} / {:d} MB available\".format(int(free/(1024*1024)), int(total/(1024*1024))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "__global__ void addKernel(float* c, float* a, float* b) {\n",
    "    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    c[i] = a[i] + b[i];\n",
    "}\n",
    "\"\"\"\n",
    "module = cuda_compiler.SourceModule(cuda_kernel)\n",
    "add_kernel = module.get_function(\"addKernel\");\n",
    "\n",
    "\n",
    "def gpuAdd(a, b):\n",
    "    c = np.empty_like(a)\n",
    "\n",
    "    #Upload data to the device\n",
    "    a_g = GPUArray(a.shape, np.float32)\n",
    "    b_g = GPUArray(b.shape, np.float32)\n",
    "    a_g.set(a)\n",
    "    b_g.set(b)\n",
    "\n",
    "    #Allocate output data\n",
    "    c_g = GPUArray(c.shape, np.float32)\n",
    "\n",
    "    #Execute program on device\n",
    "    add_kernel(c_g, a_g, b_g, block=(a.shape[0], 1, 1), grid=(1,1))\n",
    "\n",
    "    #Copy data from device to host\n",
    "    c_g.get(c)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.6, pytest-3.8.1, py-1.6.0, pluggy-0.7.1 -- /usr/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ubuntu/jupyter_notebooks, inifile:\n",
      "collecting ... collected 2 items\n",
      "\n",
      "PyTest.py::test_constants <- <ipython-input-8-4fb26c16854c> FAILED       [ 50%]\n",
      "PyTest.py::test_vector_add_gpu <- <ipython-input-8-4fb26c16854c> FAILED  [100%]\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "________________________________ test_constants ________________________________\n",
      "\n",
      "    def test_constants():\n",
      "        assert True == True\n",
      "        assert 4 == 4\n",
      ">       assert 5 == 4\n",
      "E       AssertionError\n",
      "\n",
      "<ipython-input-8-4fb26c16854c>:6: AssertionError\n",
      "_____________________________ test_vector_add_gpu ______________________________\n",
      "\n",
      "    def test_vector_add_gpu():\n",
      "        n = 50\n",
      "    \n",
      "        #Create test input / output data\n",
      "        a = np.random.rand(n).astype(np.float32)\n",
      "        b = np.random.rand(n).astype(np.float32)\n",
      ">       assert gpuAdd(a, b) == pytest.approx(a + b)\n",
      "\n",
      "<ipython-input-8-4fb26c16854c>:14: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "<ipython-input-5-abef2c313df3>:15: in gpuAdd\n",
      "    a_g = GPUArray(a.shape, np.float32)\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[AttributeError(\"'GPUArray' object has no attribute 'gpudata'\") raised in repr()] GPUArray object at 0x7f6ae50b3208>\n",
      "shape = (50,), dtype = dtype('float32')\n",
      "allocator = <Boost.Python.function object at 0x2360dd0>, base = None\n",
      "gpudata = None, strides = (4,), order = 'C'\n",
      "\n",
      "    def __init__(self, shape, dtype, allocator=drv.mem_alloc,\n",
      "            base=None, gpudata=None, strides=None, order=\"C\"):\n",
      "        dtype = np.dtype(dtype)\n",
      "    \n",
      "        try:\n",
      "            s = 1\n",
      "            for dim in shape:\n",
      "                s *= dim\n",
      "        except TypeError:\n",
      "            # handle dim-0 ndarrays:\n",
      "            if isinstance(shape, np.ndarray):\n",
      "                shape = np.asscalar(shape)\n",
      "            assert isinstance(shape, numbers.Integral)\n",
      "            s = shape\n",
      "            shape = (shape,)\n",
      "        else:\n",
      "            # handle shapes that are ndarrays\n",
      "            shape = tuple(shape)\n",
      "    \n",
      "        if isinstance(s, np.integer):\n",
      "            # bombs if s is a Python integer\n",
      "            s = np.asscalar(s)\n",
      "    \n",
      "        if strides is None:\n",
      "            if order == \"F\":\n",
      "                strides = _f_contiguous_strides(\n",
      "                        dtype.itemsize, shape)\n",
      "            elif order == \"C\":\n",
      "                strides = _c_contiguous_strides(\n",
      "                        dtype.itemsize, shape)\n",
      "            else:\n",
      "                raise ValueError(\"invalid order: %s\" % order)\n",
      "        else:\n",
      "            # FIXME: We should possibly perform some plausibility\n",
      "            # checking on 'strides' here.\n",
      "    \n",
      "            strides = tuple(strides)\n",
      "    \n",
      "        self.shape = tuple(shape)\n",
      "        self.dtype = dtype\n",
      "        self.strides = strides\n",
      "        self.mem_size = self.size = s\n",
      "        self.nbytes = self.dtype.itemsize * self.size\n",
      "        self.itemsize = self.dtype.itemsize\n",
      "    \n",
      "        self.allocator = allocator\n",
      "        if gpudata is None:\n",
      "            if self.size:\n",
      ">               self.gpudata = self.allocator(self.size * self.dtype.itemsize)\n",
      "E               pycuda._driver.LogicError: cuMemAlloc failed: invalid device context\n",
      "\n",
      "../.local/lib/python3.6/site-packages/pycuda/gpuarray.py:210: LogicError\n",
      "=========================== 2 failed in 0.19 seconds ===========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tests()\n",
    "\n",
    "def test_constants():\n",
    "    assert True == True\n",
    "    assert 4 == 4\n",
    "    assert 5 == 4\n",
    "\n",
    "def test_vector_add_gpu():\n",
    "    n = 50\n",
    "    \n",
    "    #Create test input / output data\n",
    "    a = np.random.rand(n).astype(np.float32)\n",
    "    b = np.random.rand(n).astype(np.float32)\n",
    "    assert gpuAdd(a, b) == pytest.approx(a + b)\n",
    "    \n",
    "    a = np.ones(n).astype(np.float32)\n",
    "    b = np.ones(n).astype(np.float32)\n",
    "    assert gpuAdd(a, b) == pytest.approx(2*np.ones(n))\n",
    "    \n",
    "\n",
    "run_pytest(pytest_options=['-vvv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Free the context\n",
    "context.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
